---
title: "Deliverable_03"
output: html_document
---



---
title: "Group 1 - Deliverable 03"
author: "Lyna Bentahar, Katia Pechenkina & Cameron Jones"
date: "3/12/2022"
output: html_notebook
---

The paragraphs we'll be reverse engineering are:

As Baltimore has seen a stunning surge of violence, with nearly a killing each day for the past three years in a city of 600,000, homicide arrests have plummeted. City police made an arrest in 41 percent of homicides in 2014; last year, the rate was just 27 percent, a 14 percentage point drop.
-
Community leaders and residents say that leaves hundreds of families who have been robbed of a loved one without a chance at seeing justice done. Of the 1,002 homicides between 2015 and the beginning of this year, just 252 — one out of every four — resulted in an arrest.
-
Of 50 of the nation’s largest cities, Baltimore is one of 34 where police now make homicide arrests less often than in 2014, according to a Washington Post analysis. In Chicago, the homicide arrest rate has dropped 21 percentage points, in Boston it has dropped 12 points and in St. Louis it is down 9.
-
Baltimore is also one of 30 cities that have seen an increase in homicides in recent years, with the greatest raw number increase in killings of any city other than Chicago, which has four times the population. While homicide rates remain near historical lows in most American cities, Baltimore and Chicago are now both seeing murder tallies that rival the early 2000s.
-
For most of the decade before 2015, Baltimore’s annual homicide arrest rate hovered at about 40 percent. Since 2015, the arrest rate hasn’t topped 30 percent in any year. And while most cities saw their arrest rates drop gradually, Baltimore’s decline was sudden — plummeting 15 percentage points in 2015, after Gray’s death, the largest single-year drop for any city already solving less than half its homicides.

First, we just set up all the libraries we need, and then created a dataframe for Washington Post's homicide data.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Turn off scientific notation
options(scipen=999)
library(tidyverse)
library(janitor)
library(lubridate)
```

```{r}
library(readr)
homicide_data <- read_csv("homicide-data.csv")
```

We didn't like how the way the dates were formatted, so we just changed it to year-month-date.
```{r}
homicide_data$reported_date <- ymd(homicide_data$reported_date)
  
```


Sentence: As Baltimore has seen a stunning surge of violence, with nearly a killing each day for the past three years in a city of 600,000, homicide arrests have plummeted.

We don't care about other cities in this paragraph, so we're just going to create a new dataframe that only includes homicides in Baltimore.
```{r}
homicide_data_baltimore <- homicide_data %>% 
  filter(city == "Baltimore")
```

With a quick glance of the dateframe, we know that the range of dates extends between 2007/01/01 and 2017/12/31. So, the sentence describing a killing every day for the past 3 years includes the years 2015, 2016 and 2017. So, to see the average number of killings per day, we're going to count how many homicides were recorded in those three years.
```{r}
homicide_data_baltimore %>% 
  filter(reported_date >= as.Date("2015-01-01") & reported_date <= as.Date("2017-12-31")) %>% 
  summarize(
    threeyr_homicide_amount = n(),
    homicides_per_day = threeyr_homicide_amount / (365*3)
  ) 
  
```
The homicide_per_day is 0.915, which corresponds to The Washington Post's analysis that there about one killing every day for the past 3 years.

Sentence: City police made an arrest in 41 percent of homicides in 2014; last year, the rate was just 27 percent, a 14 percentage point drop.

To find the percentage of arrests police made in 2014, we will create a dataset that just includes data from the year 2014.
```{r}
homicide_2014data <- homicide_data_baltimore %>% 
  filter(reported_date >= as.Date("2014-01-01") & reported_date <= as.Date("2014-12-31"))
```

We can then summarize the data to createa dataset that counts how many cases are listed as 'Closed by arrest,' 'Closed without arrest,' and 'Open/No arrest.'
```{r}
homicide_2014data_disposition <- homicide_2014data %>% 
  group_by(disposition) %>% 
  summarize(
    disposition_breakdown = n(),
  )
```

Then, we can just see the percentages of cases with each disposition.
```{r}
homicide_2014data_disposition %>% 
  group_by(disposition) %>% 
  summarize(
    percent_cases = disposition_breakdown / sum(homicide_2014data_disposition$disposition_breakdown) * 100
  )
  
```

We see here that the percent of cases that were closed by arrest is 40.758%, which can be rounded up to 41%, as The Washington Post described.

Finally, we want to see 'last year's' arrest rate. The article was written in 2018 and refers to the year 2017. So just as we did with the 2014 data, we will narrow our homicide_data_baltimore dataset to just the year 2017.
```{r}
homicide_2017data <- homicide_data_baltimore %>% 
  filter(reported_date >= as.Date("2017-01-01") & reported_date <= as.Date("2017-12-31"))
```

We will again break the data down to count how many cases are listed under each disposition.
```{r}
homicide_2017data_disposition <- homicide_2017data %>% 
  group_by(disposition) %>% 
  summarize(
    disposition_breakdown = n()
  )
```

And then again find the percentage of cases.
```{r}
homicide_2017data_disposition %>% 
  group_by(disposition) %>% 
  summarize(
    percent_cases = disposition_breakdown / sum(homicide_2017data_disposition$disposition_breakdown) * 100
  )
```
In 2017, we see that 27.353% of cases were closed by arrest, which can be rounded down to 27%, as The Washington Post described.

Sentence: Of the 1,002 homicides between 2015 and the beginning of this year, just 252 — one out of every four — resulted in an arrest.

We'll be running the same process for this sentence, which describes cases between 2015 and the end of 2017.
```{r}
homicide_3yrdata <- homicide_data_baltimore %>% 
  filter(reported_date >= as.Date("2015-01-01") & reported_date <= as.Date("2017-12-31"))
```

We can see that there are 1002 rows, or 1002 cases of homicide, but we can go ahead and confirm that with a simple summarize function.
```{r}
homicide_3yrdata %>% 
  summarize(
    cases_amount = n()
  )
  
```

Of those cases, we'll see how many ended in arrest by breaking down the data to see how many cases were assigned each of the three dispositions.
```{r}
homicide_3yrdata_disposition <- homicide_3yrdata %>% 
  group_by(disposition) %>% 
  summarize(
    disposition_breakdown = n()
  )
homicide_3yrdata_disposition
```
As The Washington Post describes, we can see that 252 cases were closed by arrest.

And to know the percentage of cases, we do the same as with the 2014 and 2017 data.
```{r}
homicide_3yrdata_disposition %>% 
  group_by(disposition) %>% 
  summarize(
    percent_cases = disposition_breakdown / sum(homicide_3yrdata_disposition$disposition_breakdown) * 100
  )
```
We can see here that 25.15% of cases were closed by arrest. Rounding down, that's 25% of cases, or 1 out of 4, as The Washington Post describes.

Sentence: Of 50 of the nation’s largest cities, Baltimore is one of 34 where police now make homicide arrests less often than in 2014, according to a Washington Post analysis. In Chicago, the homicide arrest rate has dropped 21 percentage points, in Boston it has dropped 12 points and in St. Louis it is down 9.

We know that the data is made up of arrest data from the 50 largest cities in the U.S. Knowing this, we're going to take the original data and compare the 2014 arrest rates of each city with the 2017 arrest rates of each city.

To make things easier on us, we're going to create a column that just lists the year of the reported date.
```{r}
homicide_data <- homicide_data %>% 
  mutate(year = year(reported_date))
```

Then, we're going to filter our data to just the years 2014 and 2017, because we're just comparing the difference in percentage between the two years. Further narrowing our data, we only comparing the city and disposition between these years, so we're going to create two new columns: One that will show the amount of cases per each disposition per city per year, and one that will show the total amount of cases per city per year. We'll take a ratio of these two numbers to know the percentage of cases. After that, since we don't care about the ratio of 'Closed without arrest' or the ratio between 'Open/No arrest' and the total number of cases, we're going to filter the data so that it only shows the percent of cases per the 'Closed by arrest' disposition.
```{r}
homicide_arrests_per_city_per_year <- homicide_data %>% 
  filter(year == "2014" | year == "2017") %>% 
  group_by(city, year, disposition) %>% 
  mutate(
    amount_of_cases_per_disposition = n()
  ) %>% 
  group_by(city, year) %>% 
  mutate(
    amount_of_cases = n(),
    percent_of_cases_per_disposition = amount_of_cases_per_disposition / amount_of_cases * 100
  ) %>% 
  filter(disposition == "Closed by arrest")
  
```

Now, we don't care about any of the columns except for city, year, and percent_of_cases_per_disposition, so we're going to create a new dataset that just selects these three columns. There's a lot of duplicate data here, so we're going to use the distinct() function to simplify our dataset.
```{r}
delta_homicide_arrests_per_city_per_year <- homicide_arrests_per_city_per_year %>% 
  select(city, year, percent_of_cases_per_disposition) %>% 
  distinct()
```


With this clean date, we're going to find the percentage change between 2014 and 2017 by simply subtracting each row by the previous row for each city using the lag() function.
```{r}
delta_homicide_arrests_per_city_per_year <- delta_homicide_arrests_per_city_per_year %>% 
  group_by(city) %>% 
  arrange(city, year, .by_group = TRUE) %>%
  mutate(delta = percent_of_cases_per_disposition - lag(percent_of_cases_per_disposition))
view(delta_homicide_arrests_per_city_per_year)
```
With this, we can see the percentage change for each city mentioned in the article: Chicago, Boston and St. Louis. In Chicago, our data shows a drop by 21.34 percentage points. Rounding down, this is a drop in 21 percentage points, as The Washington Post Described. In Boston, our data shows a drop by 11.98 percentage points, which can be rounded up to a drop by 12 percentage points, as The Washington Post described. In St. Louis, our data shows a drop by 8.94 percentage points, which can be rounded up to a drop by 9 percentage points, as The Washington Post described.

Finally, we can see that Baltimore has a drop in percentage, but we want to know how many cities it shares that distinction. So, we'll use the case_when() function to see how many cities have seen a drop in percentage.
```{r}
delta_homicide_arrests_per_city_per_year %>% 
  mutate(
    cities_with_negative_change = case_when(
      delta < 0 ~ 'negative cases',
      delta > 0 ~ 'positive cases'
    )
  ) %>% 
  group_by(cities_with_negative_change) %>% 
  summarize(
    count = n()
  )
```
Here, I was only able to find 32 cases of a drop in percentage points since 2014. Some data for some cities do not include data for either 2014 or 2017. It's possible that The Washington Post went about those cities with missing 2014 and 2017 data differently, since the article doesn't define what it means by "now."

The following considers the fourth paragraph.

Sentence:Baltimore is also one of 30 cities that have seen an increase in homicides in recent years, with the greatest raw number increase in killings of any city other than Chicago, which has four times the population. While homicide rates remain near historical lows in most American cities, Baltimore and Chicago are now both seeing murder tallies that rival the early 2000s.

```{r}
library(readr)
homicide_dataset <- read_csv("homicide-data.csv")
```
```{r}
#organize by year, month, date, then just leave the year 
homicide_dataset$reported_date <- ymd(homicide_dataset$reported_date)
homicide_dataset$reported_date <- year(homicide_dataset$reported_date)
   
```
We cleaned up the reported_date column and got rid of the day and month
Then we filtered by years 2014 and 2017 to see the "recent years" of the dataset. We focus on the cities and those years and the amount of homicides in each of those cities. Then we aggange by each given year for every city and count the decrease or increase in homicides. 

```{r}
#filter years 2014 to 2017, group by city and date, count
homicide_dataset_2014_to_2017 <- homicide_dataset  %>%
filter (reported_date == "2014" | reported_date == "2017") %>%
group_by (city, reported_date)%>%
 summarize(count=n())%>% 
group_by(city) %>% 
  arrange(city, reported_date, .by_group = TRUE) %>%
  mutate(delta = count - lag(count))
```
Here we use that dataset for 2014 and 2017 and count how many cities experienced decrease and increase in homicides. Turns out Chicago was one of 25 cities that saw an increase in those years. WP claimed it was among 30 cities, but some data might for certain cities might have been missing from their dataset.(?)
```{r}
homicide_dataset_2014_to_2017%>%
mutate(
    cities_change = case_when(
      delta < 0 ~ 'decrease',
      delta > 0 ~ 'increase'
    )
  )%>%
group_by(cities_change)%>%
  summarize(count=n())
```

The following considers the last paragraph:

Will be looking at statistics from this paragrapph "For most of the decade before 2015, Baltimore’s annual homicide arrest rate hovered at about 40 percent. Since 2015, the arrest rate hasn’t topped 30 percent in any year. And while most cities saw their arrest rates drop gradually, Baltimore’s decline was sudden — plummeting 15 percentage points in 2015, after Gray’s death, the largest single-year drop for any city already solving less than half its homicides." 



```{r}
# Turn off scientific notation
options(scipen=999)
# Load the tidyverse.
library(tidyverse)
```


read in the file from github 

```{r}
library(readr)
urlfile="https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicide_data <- read_csv(url(urlfile))
```

filter the file to only inlcude data from Baltimore

then filter that data to only look at crimes reported before 2015

```{r}
baltimore_homicide_data <- homicide_data %>% 
  filter(city == "Baltimore")
early_baltimore_homicide_data <- baltimore_homicide_data %>% 
  filter(reported_date < 20150103)
```

"
find arress rate from "most of tghe decade before 2015" to be 40%

```{r}
successful_arrests <- early_baltimore_homicide_data %>% 
  filter(str_detect(disposition ,'by arrest'))
```


We find from the 1,825 cases in  Baltimore before 2015, that 750 were closed by arrest. This means that before 2015, roughly 41% of cases ended in an arrest which checks out with the "For most of the decade before 2015, Baltimore’s annual homicide arrest rate hovered at about 40 percent" sentence.


next I will code to find the findings of the next sentence, "Since 2015, the arrest rate hasn’t topped 30 percent in any year."

filter to find arrest rate in each year, starting with 2015

```{r}
baltimore_homicide_data <- homicide_data %>% 
  filter(city == "Baltimore")
fifteen_baltimore_homicide_data <- baltimore_homicide_data %>% 
  filter(reported_date < 20159999) %>% 
  filter(reported_date > 20149999  )
##this code above gives me only cases from 2015
fifteen_successful_arrests <- fifteen_baltimore_homicide_data %>% 
  filter(str_detect(disposition ,'by arrest')) 
  
```

code above shows us that there are only 87 rows in the data (arrests) out of 342 rows (arrests) in  our other datafrome. This gives us a pervcentage of 25.4 (87/342), which is well bellow 30%. I will repeat the code for 2016 and 2017 as well. 


```{r}
baltimore_homicide_data <- homicide_data %>% 
  filter(city == "Baltimore")
sixteen_baltimore_homicide_data <- baltimore_homicide_data %>% 
  filter(reported_date < 20169999) %>% 
  filter(reported_date > 20159999  )
##this code above gives me only cases from 2016
sixteen_successful_arrests <- sixteen_baltimore_homicide_data %>% 
  filter(str_detect(disposition ,'by arrest')) 
sixteen_successful_arrests
```

code above shows us that there are only 72 rows in the data (arrests) out of 320 rows (arrests) in  our other datafrome. This gives us a pervcentage of 22.5 (72/320), which is well bellow 30%. I will repeat for 2017. 

```{r}
baltimore_homicide_data <- homicide_data %>% 
  filter(city == "Baltimore")
seventeen_baltimore_homicide_data <- baltimore_homicide_data %>% 
  filter(reported_date < 20179999) %>% 
  filter(reported_date > 20169999  )
##this code above gives me only cases from 2017
seventeen_successful_arrests <- seventeen_baltimore_homicide_data %>% 
  filter(str_detect(disposition ,'by arrest')) 
seventeen_successful_arrests
```

code above shows us that there are only 93 rows in the data (arrests) out of 340 rows (arrests) in  our other datafrome. This gives us a pervcentage of 27.35 (93/340), which is well bellow 30%. This comncludes the code for the sentence "Since 2015, the arrest rate hasn’t topped 30 percent in any year."

next I will be looking at And while most cities saw their arrest rates drop gradually, Baltimore’s decline was sudden — plummeting 15 percentage points in 2015

```{r}
baltimore_homicide_data <- homicide_data %>% 
  filter(city == "Baltimore")
fourteen_baltimore_homicide_data <- baltimore_homicide_data %>% 
  filter(reported_date < 20149999) %>% 
  filter(reported_date > 20139999  )
##this code above gives me only cases from 2017
fourteen_successful_arrests <- fourteen_baltimore_homicide_data %>% 
  filter(str_detect(disposition ,'by arrest')) 
fourteen_successful_arrests
```

data shows that in 2014, the arrest rate was 40.7% (86/211). As observed earlier, the arrest rate in 2015 was just 25.4%, an exact dropoff of 15 percent. 